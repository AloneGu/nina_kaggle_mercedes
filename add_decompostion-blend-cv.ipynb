{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (4209, 378)\n",
      "Shape test: (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# read datasets\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (4209, 438)\n",
      "Shape test: (4209, 437)\n",
      "<class 'numpy.ndarray'> (2946, 437)\n"
     ]
    }
   ],
   "source": [
    "# add pca\n",
    "from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "n_comp = 20\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train.drop([\"y\"], axis=1))\n",
    "tsvd_results_test = tsvd.transform(test)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train.drop([\"y\"], axis=1))\n",
    "grp_results_test = grp.transform(test)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train.drop([\"y\"], axis=1))\n",
    "srp_results_test = srp.transform(test)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "    train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "    \n",
    "    train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    test['srp_' + str(i)] = srp_results_test[:, i - 1]\n",
    "\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n",
    "\n",
    "x_train = train.drop([\"y\"], axis=1).values\n",
    "y_train = train['y'].values\n",
    "# split train data\n",
    "x_train_data,x_test_data,y_train_data,y_test_data = train_test_split(x_train,y_train,test_size=0.3,random_state=230)\n",
    "print(type(x_train_data),x_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from copy import copy\n",
    "    \n",
    "class StackedGeneralizer(object):\n",
    "    \"\"\"Base class for stacked generalization classifier models\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_models=None, blending_model=None, n_folds=5, verbose=True):\n",
    "        \"\"\"\n",
    "        Stacked Generalizer Classifier\n",
    "\n",
    "        Trains a series of base models using K-fold cross-validation, then combines\n",
    "        the predictions of each model into a set of features that are used to train\n",
    "        a high-level classifier model. \n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        base_models: list of classifier models\n",
    "            Each model must have a .fit and .predict_proba/.predict method a'la\n",
    "            sklearn\n",
    "        blending_model: object\n",
    "            A classifier model used to aggregate the outputs of the trained base\n",
    "            models. Must have a .fit and .predict_proba/.predict method\n",
    "        n_folds: int\n",
    "            The number of K-folds to use in =cross-validated model training\n",
    "        verbose: boolean\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "        from sklearn.datasets import load_digits\n",
    "        from stacked_generalizer import StackedGeneralizer\n",
    "        from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        import numpy as np\n",
    "\n",
    "        logger = Logger('test_stacked_generalizer')\n",
    "\n",
    "        VERBOSE = True\n",
    "        N_FOLDS = 5\n",
    "        \n",
    "        # load data and shuffle observations\n",
    "        data = load_digits()\n",
    "\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "\n",
    "        shuffle_idx = np.random.permutation(y.size)\n",
    "\n",
    "        X = X[shuffle_idx]\n",
    "        y = y[shuffle_idx]\n",
    "\n",
    "        # hold out 20 percent of data for testing accuracy\n",
    "        n_train = round(X.shape[0]*.8)\n",
    "\n",
    "        # define base models\n",
    "        base_models = [RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "                       RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "                       ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini')]\n",
    "\n",
    "        # define blending model\n",
    "        blending_model = LogisticRegression()\n",
    "\n",
    "        # initialize multi-stage model\n",
    "        sg = StackedGeneralizer(base_models, blending_model, \n",
    "                                n_folds=N_FOLDS, verbose=VERBOSE)\n",
    "\n",
    "        # fit model\n",
    "        sg.fit(X[:n_train],y[:n_train])\n",
    "\n",
    "        # test accuracy\n",
    "        pred = sg.predict(X[n_train:])\n",
    "        pred_classes = [np.argmax(p) for p in pred]\n",
    "\n",
    "        _ = sg.evaluate(y[n_train:], pred_classes)\n",
    "\n",
    "                     precision    recall  f1-score   support\n",
    "\n",
    "                  0       0.97      1.00      0.99        33\n",
    "                  1       0.97      1.00      0.99        38\n",
    "                  2       1.00      1.00      1.00        42\n",
    "                  3       1.00      0.98      0.99        41\n",
    "                  4       0.97      0.94      0.95        32\n",
    "                  5       0.95      0.98      0.96        41\n",
    "                  6       1.00      0.95      0.97        37\n",
    "                  7       0.94      0.97      0.96        34\n",
    "                  8       0.94      0.94      0.94        34\n",
    "                  9       0.96      0.96      0.96        27\n",
    "\n",
    "        avg / total       0.97      0.97      0.97       359\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.blending_model = blending_model\n",
    "        self.n_folds = n_folds\n",
    "        self.verbose = verbose\n",
    "        self.base_models_cv = []\n",
    "        self.blending_model_cv = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.fit_base_models(X, y)\n",
    "        print('fit base models done')\n",
    "        self.fit_blending_model(X, y)\n",
    "        print('fit blend model done')\n",
    "    \n",
    "    def fit_base_models(self, X, y):\n",
    "        if self.verbose:\n",
    "            print('Fitting Base Models...')\n",
    "\n",
    "        kf = list(KFold(y.shape[0], self.n_folds))\n",
    "\n",
    "        for i, model in enumerate(self.base_models):    \n",
    "            for j, (train_idx, test_idx) in enumerate(kf):\n",
    "                if self.verbose:\n",
    "                    print('Fold %d' % (j + 1))\n",
    "                # print(X.shape,min(train_idx),max(train_idx),len(train_idx),type(X))\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # add trained model to list of CV'd models\n",
    "                self.base_models_cv.append(copy(model))\n",
    "        \n",
    "\n",
    "    def fit_blending_model(self,X, y):\n",
    "        if self.verbose:\n",
    "            model_name = \"%s\" % self.blending_model.__repr__()\n",
    "            print('Fitting Blending Model:\\n%s' % model_name)\n",
    "\n",
    "        predictions = []\n",
    "        print('model cnts',len(self.base_models_cv))\n",
    "        for m in self.base_models_cv:\n",
    "            base_res = m.predict(X)\n",
    "            predictions.append(base_res)\n",
    "\n",
    "        # transpose base model output as blend model input\n",
    "        blend_x = np.array(predictions).transpose()\n",
    "        print('blend_shape',blend_x.shape)\n",
    "        kf = list(KFold(y.shape[0], self.n_folds))\n",
    "        tmp_model = self.blending_model\n",
    "        for j, (train_idx, test_idx) in enumerate(kf):\n",
    "            if self.verbose:\n",
    "                print('Fold %d' % (j + 1))\n",
    "            # print(X.shape,min(train_idx),max(train_idx),len(train_idx),type(X))\n",
    "            X_train = blend_x[train_idx]\n",
    "            y_train = y[train_idx]\n",
    "\n",
    "            tmp_model.fit(X_train, y_train)\n",
    "\n",
    "            # add trained model to list of CV'd models\n",
    "            self.blending_model_cv.append(copy(tmp_model))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # perform model averaging to get predictions\n",
    "        predictions = []\n",
    "        for m in self.base_models_cv:\n",
    "            predictions.append(m.predict(X))\n",
    "\n",
    "        # transpose base model output as blend model input\n",
    "        blend_x = np.array(predictions).transpose()\n",
    "        blend_res = np.array([m.predict(blend_x) for m in self.blending_model_cv]).transpose()\n",
    "        print('blend_res_shape',blend_res.shape)\n",
    "        pred_res = np.mean(blend_res,axis=1)\n",
    "        print('final_res_shape',pred_res.shape)\n",
    "        return pred_res\n",
    "\n",
    "    def evaluate(self, y, y_pred):\n",
    "        print(classification_report(y, y_pred))\n",
    "        print('Confusion Matrix:')\n",
    "        print(confusion_matrix(y, y_pred))\n",
    "        return accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit base models done\n",
      "model cnts 15\n",
      "blend_shape (2946, 15)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 5)\n",
      "final_res_shape (4209,)\n",
      "0.624064504635\n",
      "blend_res_shape (1263, 5)\n",
      "final_res_shape (1263,)\n",
      "0.588625916952\n",
      "blend_res_shape (4209, 5)\n",
      "final_res_shape (4209,)\n",
      "[  83.9624639   101.06069488   87.36056512 ...,   90.69801331  113.18206346\n",
      "   92.07387539] (4209,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost\n",
    "def stack_test():\n",
    "    VERBOSE = False\n",
    "    N_FOLDS = 5\n",
    "\n",
    "    base_models = [\n",
    "                   xgboost.XGBRegressor(subsample=0.95, learning_rate=0.04),\n",
    "                   xgboost.XGBRegressor(subsample=0.75, learning_rate=0.04),\n",
    "                   xgboost.XGBRegressor(subsample=0.65, learning_rate=0.04),\n",
    "                  ]\n",
    "    #blending_model = xgboost.XGBRegressor()\n",
    "    blending_model = LinearRegression()\n",
    "\n",
    "    # initialize multi-stage model\n",
    "    sg = StackedGeneralizer(base_models, blending_model, n_folds=N_FOLDS, verbose=VERBOSE)\n",
    "    sg.fit(x_train_data,y_train_data)\n",
    "    \n",
    "    print(r2_score(y_train,sg.predict(x_train).flatten()))\n",
    "    test_score = r2_score(y_test_data,sg.predict(x_test_data).flatten())\n",
    "    print(test_score)\n",
    "    pred = sg.predict(test.values).flatten()\n",
    "    print(pred,pred.shape)\n",
    "    output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': pred})\n",
    "    output.to_csv('result/cv_blend_{}.csv'.format(test_score),index=False)\n",
    "\n",
    "stack_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit base models done\n",
      "model cnts 6\n",
      "blend_shape (2946, 6)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.60181543917\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.597962534947\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  78.61691484   98.5378823    81.30592859 ...,   93.9822691   110.95421578\n",
      "   92.73007013] (4209,)\n",
      "fit base models done\n",
      "model cnts 9\n",
      "blend_shape (2946, 9)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 3)\n",
      "final_res_shape (4209,)\n",
      "0.607711292399\n",
      "blend_res_shape (1263, 3)\n",
      "final_res_shape (1263,)\n",
      "0.588461092634\n",
      "blend_res_shape (4209, 3)\n",
      "final_res_shape (4209,)\n",
      "[  79.42423125   95.59267969   80.12152572 ...,   92.19116764  111.01278085\n",
      "   92.81338837] (4209,)\n",
      "fit base models done\n",
      "model cnts 12\n",
      "blend_shape (2946, 12)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 4)\n",
      "final_res_shape (4209,)\n",
      "0.610660121912\n",
      "blend_res_shape (1263, 4)\n",
      "final_res_shape (1263,)\n",
      "0.580491699714\n",
      "blend_res_shape (4209, 4)\n",
      "final_res_shape (4209,)\n",
      "[  77.71772634   94.86208869   79.76074875 ...,   92.36736566  113.0382\n",
      "   91.81718994] (4209,)\n"
     ]
    }
   ],
   "source": [
    "def stack_fold_test(fold):\n",
    "    VERBOSE = False\n",
    "    N_FOLDS = fold\n",
    "\n",
    "    base_models = [\n",
    "                   xgboost.XGBRegressor(subsample=0.95, learning_rate=0.03),\n",
    "                   xgboost.XGBRegressor(subsample=0.75, learning_rate=0.03),\n",
    "                   xgboost.XGBRegressor(subsample=0.65, learning_rate=0.03),\n",
    "                  ]\n",
    "    #blending_model = xgboost.XGBRegressor()\n",
    "    blending_model = LinearRegression()\n",
    "\n",
    "    # initialize multi-stage model\n",
    "    sg = StackedGeneralizer(base_models, blending_model, n_folds=N_FOLDS, verbose=VERBOSE)\n",
    "    sg.fit(x_train_data,y_train_data)\n",
    "    \n",
    "    print(r2_score(y_train,sg.predict(x_train).flatten()))\n",
    "    test_score = r2_score(y_test_data,sg.predict(x_test_data).flatten())\n",
    "    print(test_score)\n",
    "    pred = sg.predict(test.values).flatten()\n",
    "    print(pred,pred.shape)\n",
    "    output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': pred})\n",
    "    output.to_csv('result/cv_blend_{}_{}.csv'.format(test_score,fold),index=False)\n",
    "\n",
    "for i in range(2,5):\n",
    "    stack_fold_test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use all data to gen res\n",
    "def all_data_stack_fold_test(fold):\n",
    "    VERBOSE = False\n",
    "    N_FOLDS = fold\n",
    "\n",
    "    base_models = [\n",
    "                   xgboost.XGBRegressor(subsample=0.95, learning_rate=0.03),\n",
    "                   xgboost.XGBRegressor(subsample=0.75, learning_rate=0.03),\n",
    "                   xgboost.XGBRegressor(subsample=0.65, learning_rate=0.03),\n",
    "                  ]\n",
    "    #blending_model = xgboost.XGBRegressor()\n",
    "    blending_model = LinearRegression()\n",
    "\n",
    "    # initialize multi-stage model\n",
    "    sg = StackedGeneralizer(base_models, blending_model, n_folds=N_FOLDS, verbose=VERBOSE)\n",
    "    sg.fit(x_train,y_train)\n",
    "    \n",
    "    print(r2_score(y_train,sg.predict(x_train).flatten()))\n",
    "    test_score = r2_score(y_test_data,sg.predict(x_test_data).flatten())\n",
    "    print(test_score)\n",
    "    pred = sg.predict(test.values).flatten()\n",
    "    print(pred,pred.shape)\n",
    "    output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': pred})\n",
    "    output.to_csv('result/all_data_cv_blend_{}_{}.csv'.format(test_score,fold),index=False)\n",
    "all_data_stack_fold_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate used 0.36\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.715807309105\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.562342410207\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  84.29193199  108.26766319   88.70576055 ...,   97.36413124  116.95089509\n",
      "   96.93272605] (4209,)\n",
      "--------------\n",
      "rate used 0.33999999999999997\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.707683874933\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.556151700712\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  85.3440809   106.69686994   86.01314138 ...,   96.65180167  117.44556325\n",
      "   96.87187643] (4209,)\n",
      "--------------\n",
      "rate used 0.32\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.708440415751\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.568490192169\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  79.62536014  104.50613183   84.84017637 ...,   97.71274246  117.40675417\n",
      "   99.21494266] (4209,)\n",
      "--------------\n",
      "rate used 0.3\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.706492716173\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.564480515997\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  81.0079197   108.93037989   90.1176362  ...,   96.80657109  116.08839474\n",
      "   98.45116934] (4209,)\n",
      "--------------\n",
      "rate used 0.27999999999999997\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.700297957102\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.569164094774\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  84.38218822  107.53419313   87.23677164 ...,   97.21324027  115.82921439\n",
      "   96.99029626] (4209,)\n",
      "--------------\n",
      "rate used 0.26\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.697351432414\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.568434653582\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  84.07570477  104.83491155   86.39329678 ...,   97.46944558  115.71041804\n",
      "   97.06001889] (4209,)\n",
      "--------------\n",
      "rate used 0.24\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.69241887403\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.573020781327\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  84.14228042  106.8515957    90.20041821 ...,   97.78185464  115.46560916\n",
      "   96.80799388] (4209,)\n",
      "--------------\n",
      "rate used 0.21999999999999997\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.68791473745\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.568543922089\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  83.74732851  103.96078075   84.23869332 ...,   94.82700105  114.21653401\n",
      "   95.4178106 ] (4209,)\n",
      "--------------\n",
      "rate used 0.19999999999999998\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.684506918189\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.577904322672\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  81.42768991  107.28635646   88.3366942  ...,   97.13546585  116.01529228\n",
      "   94.83461732] (4209,)\n",
      "--------------\n",
      "rate used 0.18\n",
      "fit base models done\n",
      "model cnts 20\n",
      "blend_shape (2946, 20)\n",
      "fit blend model done\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "0.678248778487\n",
      "blend_res_shape (1263, 2)\n",
      "final_res_shape (1263,)\n",
      "0.577087773508\n",
      "blend_res_shape (4209, 2)\n",
      "final_res_shape (4209,)\n",
      "[  83.15798657  105.16065289   86.23242264 ...,   96.53688058  117.96466402\n",
      "   96.9768966 ] (4209,)\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "def stack_sample_rate_test(rate):\n",
    "    print('rate used',rate)\n",
    "    VERBOSE = False\n",
    "    N_FOLDS = 2\n",
    "    base_models = []\n",
    "    for i in range(10,20):\n",
    "        base_models.append(xgboost.XGBRegressor(subsample=0.05*i,learning_rate=rate))\n",
    "    #blending_model = xgboost.XGBRegressor()\n",
    "    blending_model = LinearRegression()\n",
    "\n",
    "    # initialize multi-stage model\n",
    "    sg = StackedGeneralizer(base_models, blending_model, n_folds=N_FOLDS, verbose=VERBOSE)\n",
    "    sg.fit(x_train_data,y_train_data)\n",
    "    \n",
    "    print(r2_score(y_train,sg.predict(x_train).flatten()))\n",
    "    test_score = r2_score(y_test_data,sg.predict(x_test_data).flatten())\n",
    "    print(test_score)\n",
    "    pred = sg.predict(test.values).flatten()\n",
    "    print(pred,pred.shape)\n",
    "    output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': pred})\n",
    "    output.to_csv('result/cv_blend_{}_{}.csv'.format(test_score,rate),index=False)\n",
    "\n",
    "for i in range(10):\n",
    "    stack_sample_rate_test(0.36-i*0.02)\n",
    "    print('--------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
